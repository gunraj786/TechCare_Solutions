{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Core dependencies\n",
        "!pip install streamlit -q\n",
        "\n",
        "# Speech recognition + text-to-speech\n",
        "!pip install SpeechRecognition -q\n",
        "!pip install gTTS -q\n",
        "\n",
        "# Audio playback support\n",
        "!apt-get install -y portaudio19-dev -q\n",
        "!pip install pyaudio soundfile -q\n",
        "\n",
        "# Extra: to run streamlit in colab\n",
        "!pip install pyngrok -q\n",
        "!pip install -q streamlit google-generativeai PyPDF2 python-docx pillow -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_S6UJie5AYiT",
        "outputId": "19060c3f-355d-438d-b805-ec065f8c848a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "portaudio19-dev is already the newest version (19.6.0-1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update && apt-get install -y flac portaudio19-dev\n",
        "\n",
        "# Install pyaudio (might need system dependencies)\n",
        "!pip install pyaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noww6SZ1JBrZ",
        "outputId": "19f57e9e-f0d6-4497-ae51-8a45dfae3903"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [1 InRelease 14.2 kB/129\r                                                                               \rGet:2 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [1 InRelease 22.9 kB/129\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [1 InRelease 41.7 kB/129\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Waiting for headers] [1 InRelease 66.3 kB/129 kB 51%] [3 InRelease 3,632 B/\r0% [Waiting for headers] [1 InRelease 69.2 kB/129 kB 54%] [Waiting for headers]\r                                                                               \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Waiting for headers] [1 InRelease 69.2 kB/129 kB 54%] [Waiting for headers]\r0% [Waiting for headers] [1 InRelease 69.2 kB/129 kB 54%] [Waiting for headers]\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\r                                                                               \rGet:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "\r0% [Waiting for headers] [5 InRelease 6,555 B/6,555 B 100%] [Connected to ppa.l\r0% [Waiting for headers] [Connected to ppa.launchpadcontent.net (185.125.190.80\r0% [Waiting for headers] [Connected to ppa.launchpadcontent.net (185.125.190.80\r                                                                               \rHit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 https://cli.github.com/packages stable/main amd64 Packages [346 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,006 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,273 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,253 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,310 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,792 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,623 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,581 kB]\n",
            "Fetched 24.2 MB in 2s (11.0 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "portaudio19-dev is already the newest version (19.6.0-1.1).\n",
            "The following NEW packages will be installed:\n",
            "  flac\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 130 kB of archives.\n",
            "After this operation, 359 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 flac amd64 1.3.3-2ubuntu0.2 [130 kB]\n",
            "Fetched 130 kB in 1s (211 kB/s)\n",
            "Selecting previously unselected package flac.\n",
            "(Reading database ... 126418 files and directories currently installed.)\n",
            "Preparing to unpack .../flac_1.3.3-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking flac (1.3.3-2ubuntu0.2) ...\n",
            "Setting up flac (1.3.3-2ubuntu0.2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Requirement already satisfied: pyaudio in /usr/local/lib/python3.12/dist-packages (0.2.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvobHRXg_qSo",
        "outputId": "c3489ee4-4c9f-412b-813b-57d3bb946e97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "import tempfile\n",
        "import traceback\n",
        "import io\n",
        "import base64\n",
        "from typing import List\n",
        "import google.generativeai as genai\n",
        "from PIL import Image\n",
        "import PyPDF2\n",
        "import docx\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# Audio recording imports for Colab\n",
        "try:\n",
        "    from google.colab import output\n",
        "    from IPython.display import Javascript, HTML, display, Audio\n",
        "    import numpy as np\n",
        "    import wave\n",
        "    COLAB_ENV = True\n",
        "except ImportError:\n",
        "    COLAB_ENV = False\n",
        "\n",
        "# Page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"Medical Chatbot - Gemini 1.5 Flash\",\n",
        "    page_icon=\"ü§ñ\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Custom CSS for better UI\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .stApp > header {\n",
        "        background-color: transparent;\n",
        "    }\n",
        "    .main-header {\n",
        "        font-size: 2.5rem;\n",
        "        font-weight: bold;\n",
        "        text-align: center;\n",
        "        margin-bottom: 2rem;\n",
        "        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);\n",
        "        -webkit-background-clip: text;\n",
        "        -webkit-text-fill-color: transparent;\n",
        "        background-clip: text;\n",
        "    }\n",
        "    .chat-message {\n",
        "        padding: 1rem;\n",
        "        border-radius: 10px;\n",
        "        margin: 0.5rem 0;\n",
        "    }\n",
        "    .user-message {\n",
        "        background-color: #e3f2fd;\n",
        "        border-left: 4px solid #2196f3;\n",
        "    }\n",
        "    .assistant-message {\n",
        "        background-color: #f3e5f5;\n",
        "        border-left: 4px solid #9c27b0;\n",
        "    }\n",
        "    .stButton > button {\n",
        "        width: 100%;\n",
        "        border-radius: 10px;\n",
        "        border: 1px solid #ddd;\n",
        "        padding: 0.5rem;\n",
        "        font-weight: 500;\n",
        "    }\n",
        "    .audio-recorder {\n",
        "        background-color: #f8f9fa;\n",
        "        padding: 1rem;\n",
        "        border-radius: 8px;\n",
        "        border: 1px solid #dee2e6;\n",
        "        margin: 1rem 0;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Initialize session state\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "if \"gemini_api_key\" not in st.session_state:\n",
        "    st.session_state.gemini_api_key = \"\"\n",
        "if \"model\" not in st.session_state:\n",
        "    st.session_state.model = None\n",
        "\n",
        "def configure_gemini(api_key: str):\n",
        "    \"\"\"Configure Gemini AI with API key\"\"\"\n",
        "    try:\n",
        "        genai.configure(api_key=api_key)\n",
        "        model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error configuring Gemini: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def extract_text_from_pdf(file_path: str) -> str:\n",
        "    \"\"\"Extract text from PDF file\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading PDF: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "def extract_text_from_docx(file_path: str) -> str:\n",
        "    \"\"\"Extract text from DOCX file\"\"\"\n",
        "    try:\n",
        "        doc = docx.Document(file_path)\n",
        "        text = \"\"\n",
        "        for paragraph in doc.paragraphs:\n",
        "            text += paragraph.text + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading DOCX: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "def process_uploaded_files(uploaded_files) -> str:\n",
        "    \"\"\"Process uploaded files and extract text\"\"\"\n",
        "    combined_text = \"\"\n",
        "\n",
        "    if not uploaded_files:\n",
        "        return combined_text\n",
        "\n",
        "    for file in uploaded_files:\n",
        "        try:\n",
        "            # Save uploaded file temporarily\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.name)[1]) as tmp_file:\n",
        "                tmp_file.write(file.getvalue())\n",
        "                tmp_file_path = tmp_file.name\n",
        "\n",
        "            # Extract text based on file type\n",
        "            if file.type == \"application/pdf\":\n",
        "                text = extract_text_from_pdf(tmp_file_path)\n",
        "            elif file.type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
        "                text = extract_text_from_docx(tmp_file_path)\n",
        "            elif file.type.startswith(\"text/\"):\n",
        "                with open(tmp_file_path, 'r', encoding='utf-8') as f:\n",
        "                    text = f.read()\n",
        "            elif file.type.startswith(\"image/\"):\n",
        "                # For images, we'll handle them separately in the main function\n",
        "                text = f\"[Image file: {file.name}]\"\n",
        "            else:\n",
        "                text = f\"[Unsupported file type: {file.name}]\"\n",
        "\n",
        "            combined_text += f\"\\n--- Content from {file.name} ---\\n{text}\\n\"\n",
        "\n",
        "            # Clean up\n",
        "            os.unlink(tmp_file_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error processing {file.name}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    return combined_text\n",
        "\n",
        "def get_gemini_response(prompt: str, file_content: str = \"\", images: List = None) -> str:\n",
        "    \"\"\"Get response from Gemini 1.5 Flash\"\"\"\n",
        "    try:\n",
        "        if not st.session_state.model:\n",
        "            return \"‚ùå Please configure your Gemini API key first.\"\n",
        "\n",
        "        # Prepare the full prompt with context\n",
        "        full_prompt = f\"\"\"You are a helpful medical chatbot assistant. Please provide accurate, informative, and helpful responses.\n",
        "\n",
        "Important: Always remind users to consult with healthcare professionals for serious medical concerns.\n",
        "\n",
        "User Query: {prompt}\n",
        "\n",
        "Additional Context from uploaded files:\n",
        "{file_content if file_content else 'No additional files provided.'}\n",
        "\n",
        "Please provide a comprehensive and helpful response:\"\"\"\n",
        "\n",
        "        # If images are provided, include them in the request\n",
        "        if images:\n",
        "            content = [full_prompt] + images\n",
        "        else:\n",
        "            content = full_prompt\n",
        "\n",
        "        response = st.session_state.model.generate_content(content)\n",
        "        return response.text\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error generating response: {str(e)}\"\n",
        "\n",
        "# JavaScript for audio recording in Colab\n",
        "def get_audio_recorder_js():\n",
        "    return \"\"\"\n",
        "    <div id=\"audio-recorder\">\n",
        "        <button id=\"recordButton\" onclick=\"toggleRecording()\">üé§ Start Recording</button>\n",
        "        <button id=\"stopButton\" onclick=\"stopRecording()\" disabled>‚èπÔ∏è Stop Recording</button>\n",
        "        <div id=\"status\">Ready to record</div>\n",
        "        <audio id=\"audioPlayback\" controls style=\"display:none;\"></audio>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "    let mediaRecorder;\n",
        "    let audioChunks = [];\n",
        "    let isRecording = false;\n",
        "\n",
        "    async function toggleRecording() {\n",
        "        if (!isRecording) {\n",
        "            try {\n",
        "                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
        "                mediaRecorder = new MediaRecorder(stream);\n",
        "\n",
        "                mediaRecorder.ondataavailable = event => {\n",
        "                    audioChunks.push(event.data);\n",
        "                };\n",
        "\n",
        "                mediaRecorder.onstop = async () => {\n",
        "                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });\n",
        "                    const audioUrl = URL.createObjectURL(audioBlob);\n",
        "                    const audioElement = document.getElementById('audioPlayback');\n",
        "                    audioElement.src = audioUrl;\n",
        "                    audioElement.style.display = 'block';\n",
        "\n",
        "                    // Convert to base64 and send to Python\n",
        "                    const reader = new FileReader();\n",
        "                    reader.onloadend = function() {\n",
        "                        const base64Audio = reader.result.split(',')[1];\n",
        "                        google.colab.kernel.invokeFunction('handle_audio', [base64Audio], {});\n",
        "                    };\n",
        "                    reader.readAsDataURL(audioBlob);\n",
        "                };\n",
        "\n",
        "                mediaRecorder.start();\n",
        "                isRecording = true;\n",
        "                document.getElementById('recordButton').disabled = true;\n",
        "                document.getElementById('stopButton').disabled = false;\n",
        "                document.getElementById('status').textContent = 'üî¥ Recording...';\n",
        "\n",
        "            } catch (err) {\n",
        "                console.error('Error accessing microphone:', err);\n",
        "                document.getElementById('status').textContent = '‚ùå Error accessing microphone';\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    function stopRecording() {\n",
        "        if (mediaRecorder && isRecording) {\n",
        "            mediaRecorder.stop();\n",
        "            isRecording = false;\n",
        "            document.getElementById('recordButton').disabled = false;\n",
        "            document.getElementById('stopButton').disabled = true;\n",
        "            document.getElementById('status').textContent = '‚èπÔ∏è Recording stopped';\n",
        "            audioChunks = [];\n",
        "        }\n",
        "    }\n",
        "    </script>\n",
        "    \"\"\"\n",
        "\n",
        "# Main header\n",
        "st.markdown('<h1 class=\"main-header\">ü§ñ Medical Chatbot - Gemini 1.5 Flash</h1>', unsafe_allow_html=True)\n",
        "\n",
        "# Sidebar configuration\n",
        "with st.sidebar:\n",
        "    st.header(\"‚öôÔ∏è Configuration\")\n",
        "\n",
        "    # Gemini API Key input\n",
        "    api_key = st.text_input(\n",
        "        \"üîë Gemini API Key\",\n",
        "        value=st.session_state.gemini_api_key,\n",
        "        type=\"password\",\n",
        "        help=\"Get your API key from https://makersuite.google.com/app/apikey\"\n",
        "    )\n",
        "\n",
        "    if api_key and api_key != st.session_state.gemini_api_key:\n",
        "        st.session_state.gemini_api_key = api_key\n",
        "        st.session_state.model = configure_gemini(api_key)\n",
        "        if st.session_state.model:\n",
        "            st.success(\"‚úÖ Gemini configured successfully!\")\n",
        "        else:\n",
        "            st.error(\"‚ùå Failed to configure Gemini\")\n",
        "\n",
        "    st.divider()\n",
        "\n",
        "    # File upload\n",
        "    st.subheader(\"üìé Upload Files\")\n",
        "    uploaded_files = st.file_uploader(\n",
        "        \"Upload medical documents, images, or text files\",\n",
        "        accept_multiple_files=True,\n",
        "        type=['pdf', 'docx', 'txt', 'png', 'jpg', 'jpeg', 'gif'],\n",
        "        help=\"Supported: PDF, DOCX, TXT, Images\"\n",
        "    )\n",
        "\n",
        "    if uploaded_files:\n",
        "        st.success(f\"‚úÖ {len(uploaded_files)} file(s) uploaded\")\n",
        "\n",
        "    st.divider()\n",
        "\n",
        "    # Voice input section (Colab-specific)\n",
        "    st.subheader(\"üé§ Voice Input\")\n",
        "    if COLAB_ENV:\n",
        "        st.info(\"Voice input available in Colab environment\")\n",
        "        if st.button(\"üé§ Enable Voice Recording\"):\n",
        "            st.components.v1.html(get_audio_recorder_js(), height=200)\n",
        "    else:\n",
        "        st.warning(\"Voice input optimized for Google Colab\")\n",
        "\n",
        "    st.divider()\n",
        "\n",
        "    # Clear chat button\n",
        "    if st.button(\"üóëÔ∏è Clear Chat History\"):\n",
        "        st.session_state.messages = []\n",
        "        st.rerun()\n",
        "\n",
        "# Display chat messages\n",
        "for i, message in enumerate(st.session_state.messages):\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "# Audio handling function for Colab\n",
        "def handle_audio(base64_audio):\n",
        "    \"\"\"Handle audio input from JavaScript in Colab\"\"\"\n",
        "    try:\n",
        "        # Decode base64 audio\n",
        "        audio_data = base64.b64decode(base64_audio)\n",
        "\n",
        "        # Save as temporary file\n",
        "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp_file:\n",
        "            tmp_file.write(audio_data)\n",
        "            tmp_file_path = tmp_file.name\n",
        "\n",
        "        # Here you would typically use speech recognition\n",
        "        # For now, we'll just acknowledge the audio\n",
        "        st.info(\"üéµ Audio received! (Speech-to-text conversion would happen here)\")\n",
        "\n",
        "        # Clean up\n",
        "        os.unlink(tmp_file_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error processing audio: {str(e)}\")\n",
        "\n",
        "# Register the audio handler for Colab\n",
        "if COLAB_ENV:\n",
        "    output.register_callback('handle_audio', handle_audio)\n",
        "\n",
        "# Main chat interface\n",
        "prompt = st.chat_input(\"üí¨ Ask me anything about medical topics...\")\n",
        "\n",
        "if prompt:\n",
        "    # Add user message to chat history\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "    # Display user message\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(prompt)\n",
        "\n",
        "    # Process uploaded files\n",
        "    file_content = \"\"\n",
        "    images = []\n",
        "\n",
        "    if uploaded_files:\n",
        "        with st.spinner(\"üìÇ Processing uploaded files...\"):\n",
        "            file_content = process_uploaded_files(uploaded_files)\n",
        "\n",
        "            # Handle images separately\n",
        "            for file in uploaded_files:\n",
        "                if file.type.startswith(\"image/\"):\n",
        "                    try:\n",
        "                        image = Image.open(file)\n",
        "                        images.append(image)\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"Error processing image {file.name}: {str(e)}\")\n",
        "\n",
        "    # Generate and display assistant response\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        with st.spinner(\"ü§î Thinking...\"):\n",
        "            try:\n",
        "                response = get_gemini_response(prompt, file_content, images)\n",
        "                st.markdown(response)\n",
        "\n",
        "                # Add assistant response to chat history\n",
        "                st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "            except Exception as e:\n",
        "                error_msg = f\"‚ö† Error generating response: {str(e)}\"\n",
        "                st.error(error_msg)\n",
        "                st.session_state.messages.append({\"role\": \"assistant\", \"content\": error_msg})\n",
        "\n",
        "                # Show detailed error in expander for debugging\n",
        "                with st.expander(\"üîç Debug Information\"):\n",
        "                    st.code(traceback.format_exc())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok_token = \"30LsGu06oX4YgWEJd6z30DNO1kB_5C5VX4h5YGt3rFAUmRAqn\"  # Replace with your actual token\n",
        "\n",
        "\n",
        "\n",
        "# 4: Run Your App (With sharing - requires ngrok token)\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "import time\n",
        "\n",
        "import threading\n",
        "\n",
        "\n",
        "\n",
        "# Set your ngrok authentication token (replace ngrok_token with your actual token)\n",
        "\n",
        "ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "\n",
        "\n",
        "# Function to launch the Streamlit app using a system command\n",
        "\n",
        "def run_app():\n",
        "\n",
        "    !streamlit run app.py --server.headless true --server.port 8501\n",
        "\n",
        "\n",
        "\n",
        "# Terminate any active ngrok tunnels before starting a new one\n",
        "\n",
        "ngrok.kill()\n",
        "\n",
        "\n",
        "\n",
        "# Start the Streamlit app in a separate thread so the script can continue running\n",
        "\n",
        "app_thread = threading.Thread(target=run_app)\n",
        "\n",
        "app_thread.start()\n",
        "\n",
        "\n",
        "\n",
        "# Allow time for the Streamlit app to fully start before creating the tunnel\n",
        "\n",
        "time.sleep(10)\n",
        "\n",
        "\n",
        "\n",
        "# Create a public URL using ngrok and display it\n",
        "\n",
        "try:\n",
        "\n",
        "    public_url = ngrok.connect(8501)\n",
        "\n",
        "    print(\"üöÄ Your app is live!\")\n",
        "\n",
        "    print(f\"üåê Share this link: {public_url}\")\n",
        "\n",
        "    print(\"üì± Anyone can access your app with this link!\")\n",
        "\n",
        "except:\n",
        "\n",
        "    print(\"‚ö†Ô∏è Need ngrok token for sharing. App is running locally.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmYf99Hk_8z0",
        "outputId": "d1492313-5e08-44c6-9c3c-d080c166efd2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "2025-09-11 09:39:38.715 Port 8501 is already in use\n",
            "üöÄ Your app is live!\n",
            "üåê Share this link: NgrokTunnel: \"https://f7f3e2ad7bc3.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "üì± Anyone can access your app with this link!\n"
          ]
        }
      ]
    }
  ]
}